{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ff85cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper) (0.57.1)\n",
      "Requirement already satisfied: numpy in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper) (1.24.3)\n",
      "Collecting torch (from openai-whisper)\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/3e/b9/256ab23c859cbcd7d6fb7cb46417a07eac817881a0a68df8ea0c18f45221/torch-2.2.1-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.2.1-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tqdm in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper) (8.12.0)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/9e/11/83ca4e19bb6fc15971e543725ae1269a8a1c133e55b5952801ab9c0bcc9e/tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from numba->openai-whisper) (0.40.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch->openai-whisper)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from jinja2->torch->openai-whisper) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (949 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.1-cp311-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801344 sha256=ea750f29e175590477e798a6c93c09325ed9dc41d514ccc51b417691a85f6452\n",
      "  Stored in directory: /Users/kulyashdahiya/Library/Caches/pip/wheels/55/5d/42/c296ab046d52caa0adc0e3f159e98f011b3994a022d6282105\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: typing-extensions, torch, tiktoken, openai-whisper\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed openai-whisper-20231117 tiktoken-0.6.0 torch-2.2.1 typing-extensions-4.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d690a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-req-build-169gnaf_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-req-build-169gnaf_\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper==20231117) (0.57.1)\n",
      "Requirement already satisfied: numpy in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper==20231117) (1.24.3)\n",
      "Requirement already satisfied: torch in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper==20231117) (2.2.1)\n",
      "Requirement already satisfied: tqdm in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper==20231117) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper==20231117) (8.12.0)\n",
      "Requirement already satisfied: tiktoken in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from openai-whisper==20231117) (0.6.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from numba->openai-whisper==20231117) (0.40.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper==20231117) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05392b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-req-build-hw79ttbi\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-req-build-hw79ttbi\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=6eab45415c8092fa778a179a02dac5f86e9a9234ffddd390f4f4296261d13170\n",
      "  Stored in directory: /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-ephem-wheel-cache-b_76m_90/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: openai-whisper\n",
      "  Attempting uninstall: openai-whisper\n",
      "    Found existing installation: openai-whisper 20231117\n",
      "    Uninstalling openai-whisper-20231117:\n",
      "      Successfully uninstalled openai-whisper-20231117\n",
      "Successfully installed openai-whisper-20231117\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09d8512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools-rust\n",
      "  Obtaining dependency information for setuptools-rust from https://files.pythonhosted.org/packages/f7/7f/8b1c33598b03ad612b8ced223f9ca54076b789fabf5a66ce37cc096d9cf7/setuptools_rust-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading setuptools_rust-1.9.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: setuptools>=62.4 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from setuptools-rust) (68.0.0)\n",
      "Collecting semantic-version<3,>=2.8.2 (from setuptools-rust)\n",
      "  Obtaining dependency information for semantic-version<3,>=2.8.2 from https://files.pythonhosted.org/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Downloading setuptools_rust-1.9.0-py3-none-any.whl (26 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: semantic-version, setuptools-rust\n",
      "Successfully installed semantic-version-2.10.0 setuptools-rust-1.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c6812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/kulyashdahiya/Beginning/AI/Untitled Folder\n",
      "File Path: /Users/kulyashdahiya/Beginning/AI/Untitled Folder/audio.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)\n",
    "\n",
    "# Get the absolute path of a file in the current directory\n",
    "file_name = \"audio.mp3\"\n",
    "file_path = os.path.join(current_directory, file_name)\n",
    "print(\"File Path:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738f6fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:05<00:00, 13.0MiB/s]\n",
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiny\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/kulyashdahiya/Beginning/AI/Untitled Folder/audio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:279\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    276\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m    278\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 279\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m decode_with_fallback(mel_segment)\n\u001b[1;32m    280\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:195\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    192\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    194\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m--> 195\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(segment, options)\n\u001b[1;32m    197\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    199\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[1;32m    201\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m DecodingTask(model, options)\u001b[38;5;241m.\u001b[39mrun(mel)\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_main_loop(audio_features, tokens)\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/decoding.py:687\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[0;32m--> 687\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference\u001b[38;5;241m.\u001b[39mlogits(tokens, audio_features)\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdecoder(tokens, audio_features, kv_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkv_cache)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/model.py:211\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    208\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 211\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x, xa, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)\n\u001b[1;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m    214\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    215\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/model.py:139\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[1;32m    138\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 139\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_ln(x))\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/whisper/model.py:37\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\n\u001b[1;32m     38\u001b[0m         x,\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     41\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny\")\n",
    "result = model.transcribe(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/audio.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e80fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Obtaining dependency information for pydub from https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd898d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "\n",
    "# Load the audio file\n",
    "audio_file_path = \"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/audio.mp3\"\n",
    "audio = AudioSegment.from_mp3(audio_file_path)\n",
    "\n",
    "# Trim the audio to 2 minutes\n",
    "two_minutes = 2 * 60 * 1000  # 2 minutes in milliseconds\n",
    "trimmed_audio = audio[:two_minutes]\n",
    "\n",
    "# Export the trimmed audio to a temporary file\n",
    "trimmed_audio.export(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db74657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " पर्दिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदि जिदिदिदिदिदिदिदिदिदिदिदिदिदिल飽anic冇त का起 वो वोभhood य 빨 currently इ dicen ांटिदिदिदिल飽 complimentaryunkenयभाल कदिदिदिदियbeanन कन आषिलोड का इंट मेulsion करसतीन परे यिदित्य। पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पाट पा पाट पाट पाट हो�GLENE प Care Break And So The iba. DANIELLEGRE P faj ऐய cricket Р幫rude занya\n"
     ]
    }
   ],
   "source": [
    "# Transcribe using whisper\n",
    "model = whisper.load_model(\"tiny\")\n",
    "result = model.transcribe(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c6a538f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [04:46<00:00, 10.8MiB/s]\n",
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " कि इडली सांबर कहां से खाया आज मार्केट चले गए थे मार्केट ऐसे किसी काम थे या कुछ कुछ काम भी था वह बेट को ना इन और यह बूलन पहन के रेशनल जा रहे हैं अच्छा वह क्योंकि रात में भी ऐसी सो जा रहे ना भी आधार नहीं है मैं गोजरी कोटन की बोटा यहां पर यहां वह भूलन पहन रहे हैं तो उससे वह ज्यादा वैसे इसके में एलर्जी टाइप हो रही थी तो मैं कुछ कॉटन का देखने गई थी अंदर मिलता है मिला कुछ वह तो नहीं मिला थी तो चाहिए थी फुल स्लिप्स की कॉटन टीशर्ट चाहिए वह नहीं मिली बट एक टॉप टाइप मिल गया तो यहां के रहने वाले हैं कि यहां से वैसे मतलब पब्लिक ट्रांसपोर्ट से तो चार पांच गंटे लग जाते हैं पर अपने वेहिकल्स दीन गंटे निशान पींगे ठीक है आराम से पीड़ी अराम से कब आया मार्केट से लुट रिसर आ गई तीज ने वैटिविटी विडियो मेडिसीन मगाई थी लोगों ने नोट विल नहीं ली थी तो वह शाप्त लेता है उसको मैंने भेजा हुआ था वह रेंज करने निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान निशान ठीक है आपसे कुछ वही क्वेश्चन से पूछूंगी मैं इंग्लिश हिंदी किसमें बताइए आप किसी में भी पूछ ले चलिए इंदी भी पूछ लीजिए आप बताए तो हिंदी गैंड हिंदी में आप आप आराम से रिलैक्स होकर जो आपको लगता है जानो ना वहीं बताएगा पर पहला प्रश्ना आपसे रोगी के झाल झाल झाल झाल झाल\n"
     ]
    }
   ],
   "source": [
    "# Transcribe using whisper\n",
    "model = whisper.load_model(\"large\")\n",
    "result = model.transcribe(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b296f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement deepspeech (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for deepspeech\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0cf6150",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepspeech'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeepspeech\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/kulyashdahiya/Beginning/AI/Untitled Folder/audio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepspeech'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import deepspeech\n",
    "\n",
    "# Load the audio file\n",
    "audio_file_path = \"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/audio.mp3\"\n",
    "audio = AudioSegment.from_mp3(audio_file_path)\n",
    "\n",
    "# Trim the audio to 2 minutes\n",
    "two_minutes = 2 * 60 * 1000  # 2 minutes in milliseconds\n",
    "trimmed_audio = audio[:two_minutes]\n",
    "\n",
    "# Export the trimmed audio to a temporary file\n",
    "trimmed_audio.export(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.wav\", format=\"wav\")\n",
    "\n",
    "# Transcribe using Mozilla DeepSpeech\n",
    "model_path = \"path_to_deepspeech_model.pbmm\"\n",
    "scorer_path = \"path_to_deepspeech_scorer.scorer\"\n",
    "\n",
    "model = deepspeech.Model(model_path)\n",
    "model.enableExternalScorer(scorer_path)\n",
    "\n",
    "with open(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.wav\", \"rb\") as f:\n",
    "    audio = f.read()\n",
    "\n",
    "result = model.stt(audio)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6c23474",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "\n",
    "# Load the audio file\n",
    "audio_file_path = \"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/audio.mp3\"\n",
    "audio = AudioSegment.from_mp3(audio_file_path)\n",
    "\n",
    "# Trim the audio to 2 minutes\n",
    "two_minutes = 2 * 60 * 1000  # 2 minutes in milliseconds\n",
    "trimmed_audio = audio[:two_minutes]\n",
    "\n",
    "# Export the trimmed audio to a temporary file\n",
    "trimmed_audio.export(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20034cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " पर्दिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदिदि औ ICISIS Systems Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Ar Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi. Armi Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi coming back to sleep soon. Armi Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armi, Armer, Armi, Armi, Armi Shakt\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny\")\n",
    "\n",
    "# Transcribe and translate the audio file\n",
    "result = model.transcribe(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3\", language=\"Hindi\")\n",
    "\n",
    "# Print the translated text\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3699aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is idli sambar. Where did you eat it from? I went to the market today. Market? Was there any work? There was some work. They were wearing woolen and doing rashes. Because they are sleeping like this at night, I don't have such habits. I put cotton in it. I understand. Here you are wearing woolen only. I was getting allergic to this skin. So I went to see cotton. Did you get anything? I didn't get the cotton t-shirt of full sleeves. But I got a top type. So I thought let's work with this. That's true. Where are you going to stay? Karshipur. How far is it from here? From here, it takes 4-5 hours from public transport. But it takes 3-4 hours from our vehicle. Will you have fun? I will have a little. Have a little. When did you come from the market? I came from the market when I was sitting downstairs. They had ordered a medicine but I couldn't get it. I had sent the person who was with me. I had to arrange that. Did you apply it from downstairs? I just came from downstairs. Yes, I was telling you. It's okay. Are you ready? Yes. Is it free? Yes. I will ask you the same questions. In English or Hindi? Ask in Hindi. It will be more comfortable to tell. If you tell, then in Hindi only. Yes, it's okay. You relax and tell whatever you feel like. Think about the theme. I will tell you the theme. Okay. Relax and tell whatever you feel like. Think about the theme. Tell whatever you feel like. Tell the theme. My first question is for you. What are the symptoms of a patient?\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "\n",
    "# Transcribe and translate the audio file\n",
    "result = model.transcribe(\"/Users/kulyashdahiya/Beginning/AI/Untitled Folder/trimmed_audio.mp3\", language=\"Hindi\", task=\"translate\")\n",
    "\n",
    "# Print the translated text\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cabe36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text = result[\"text\"]\n",
    "\n",
    "# Save the translated text to a text file\n",
    "output_file_path = \"/Users/kulyashdahiya/Desktop/translated_output1.txt\"\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    # Split the translated text into sentences\n",
    "    sentences = translated_text.split(\".\")\n",
    "    # Write each sentence to the text file\n",
    "    for sentence in sentences:\n",
    "        output_file.write(sentence.strip() + \".\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "359f8c3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/m-bain/whisperx.git\n",
      "  Cloning https://github.com/m-bain/whisperx.git to /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-req-build-rbx176r1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-req-build-rbx176r1\n",
      "  Resolved https://github.com/m-bain/whisperx.git to commit 78dcfaab51005aa703ee21375f81ed31bc248560\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from whisperx==3.1.1) (2.2.1)\n",
      "Collecting torchaudio>=2 (from whisperx==3.1.1)\n",
      "  Obtaining dependency information for torchaudio>=2 from https://files.pythonhosted.org/packages/8d/23/285f4566c0ab1c0499f88bbfa69d896a3546ed757f177b829a9fd4fac28f/torchaudio-2.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchaudio-2.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting faster-whisper==1.0.0 (from whisperx==3.1.1)\n",
      "  Obtaining dependency information for faster-whisper==1.0.0 from https://files.pythonhosted.org/packages/07/a8/a5c6f24304010a67a54c5a90c99fbec07c31362ec89066b1a7d8ab310a00/faster_whisper-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading faster_whisper-1.0.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: transformers in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from whisperx==3.1.1) (4.32.1)\n",
      "Requirement already satisfied: pandas in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from whisperx==3.1.1) (2.0.3)\n",
      "Requirement already satisfied: setuptools>=65 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from whisperx==3.1.1) (68.0.0)\n",
      "Requirement already satisfied: nltk in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from whisperx==3.1.1) (3.8.1)\n",
      "Collecting pyannote.audio==3.1.1 (from whisperx==3.1.1)\n",
      "  Obtaining dependency information for pyannote.audio==3.1.1 from https://files.pythonhosted.org/packages/f5/11/611c32f7b7894ba588ade502525d0130f3e731d15f925e9f2a1ae66c8680/pyannote.audio-3.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pyannote.audio-3.1.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting av==11.* (from faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Obtaining dependency information for av==11.* from https://files.pythonhosted.org/packages/a5/e1/9dac2ed9ec0c4317937c856c3c079959c986a34ef4bc92e9d8deba15b84c/av-11.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading av-11.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting ctranslate2<5,>=4.0 (from faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Obtaining dependency information for ctranslate2<5,>=4.0 from https://files.pythonhosted.org/packages/d8/aa/7f22e9aa783b0b150179110f42141b825ffedcf078da50151461731606fa/ctranslate2-4.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading ctranslate2-4.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.15.1)\n",
      "Requirement already satisfied: tokenizers<0.16,>=0.13 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.13.2)\n",
      "Collecting onnxruntime<2,>=1.14 (from faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Obtaining dependency information for onnxruntime<2,>=1.14 from https://files.pythonhosted.org/packages/89/82/4744bcdefd82e910d530d9f220fd8583d883e2275b6828bc25876051b28c/onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl.metadata\n",
      "  Downloading onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.2 kB)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for asteroid-filterbanks>=0.4 from https://files.pythonhosted.org/packages/c5/7c/83ff6046176a675e6a1e8aeefed8892cd97fe7c46af93cc540d1b24b8323/asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting einops>=0.6.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for einops>=0.6.0 from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for lightning>=2.0.1 from https://files.pythonhosted.org/packages/0f/bc/7a57f8ec4573b85d62a2c637c4673ff3177759ef91e540a5097c10030f06/lightning-2.2.0.post0-py3-none-any.whl.metadata\n",
      "  Downloading lightning-2.2.0.post0-py3-none-any.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<3.0,>=2.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for omegaconf<3.0,>=2.1 from https://files.pythonhosted.org/packages/e3/94/1843518e420fa3ed6919835845df698c7e27e183cb997394e4a670973a65/omegaconf-2.3.0-py3-none-any.whl.metadata\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pyannote.core>=5.0.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for pyannote.core>=5.0.0 from https://files.pythonhosted.org/packages/84/c4/370bc8ba66815a5832ece753a1009388bb07ea353d21c83f2d5a1a436f2c/pyannote.core-5.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.database>=5.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for pyannote.database>=5.0.1 from https://files.pythonhosted.org/packages/eb/62/e16086c9a5c8d0a11cd9fe1709675dc193fe65e448647e12218d5bce00b0/pyannote.database-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pyannote.database-5.0.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting pyannote.metrics>=3.2 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for pyannote.metrics>=3.2 from https://files.pythonhosted.org/packages/6c/7d/035b370ab834b30e849fe9cd092b7bd7f321fcc4a2c56b84e96476b7ede5/pyannote.metrics-3.2.1-py3-none-any.whl.metadata\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for pyannote.pipeline>=3.0.1 from https://files.pythonhosted.org/packages/83/42/1bf7cbf061ed05c580bfb63bffdd3f3474cbd5c02bee4fac518eea9e9d9e/pyannote.pipeline-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for pytorch-metric-learning>=2.1.0 from https://files.pythonhosted.org/packages/2c/22/d48f4fd53e0636ba2ccf862b6af842097e1731702a907102762dff228e47/pytorch_metric_learning-2.4.1-py3-none-any.whl.metadata\n",
      "  Downloading pytorch_metric_learning-2.4.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rich>=12.0.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for rich>=12.0.0 from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for semver>=3.0.0 from https://files.pythonhosted.org/packages/9a/77/0cc7a8a3bc7e53d07e8f47f147b92b0960e902b8254859f4aee5c4d7866b/semver-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting soundfile>=0.12.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for soundfile>=0.12.1 from https://files.pythonhosted.org/packages/71/87/31d2b9ed58975cec081858c01afaa3c43718eb0f62b5698a876d94739ad0/soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (14 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting speechbrain>=0.5.14 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for speechbrain>=0.5.14 from https://files.pythonhosted.org/packages/90/ee/c8669b57ebdbeac0530538725caa02cd226e2623b725f1e216ae59b54a1f/speechbrain-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading speechbrain-1.0.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for tensorboardX>=2.6 from https://files.pythonhosted.org/packages/44/71/f3e7c9b2ab67e28c572ab4e9d5fa3499e0d252650f96d8a3a03e26677f53/tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for torch-audiomentations>=0.11.0 from https://files.pythonhosted.org/packages/88/2c/03ffe92c8c28e4511c7f8108decb2065b9ee7c0ee69bfeb66325b2b4d513/torch_audiomentations-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading torch_audiomentations-0.11.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for torchmetrics>=0.11.0 from https://files.pythonhosted.org/packages/cd/23/4bb4c1b78b57682a1309974a29bfdcbfa6fcf5476e698a4f0f22affa3799/torchmetrics-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading torchmetrics-1.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx==3.1.1) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx==3.1.1) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx==3.1.1) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx==3.1.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx==3.1.1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx==3.1.1) (2023.4.0)\n",
      "Requirement already satisfied: click in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from nltk->whisperx==3.1.1) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from nltk->whisperx==3.1.1) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from nltk->whisperx==3.1.1) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from nltk->whisperx==3.1.1) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pandas->whisperx==3.1.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pandas->whisperx==3.1.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pandas->whisperx==3.1.1) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pandas->whisperx==3.1.1) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from transformers->whisperx==3.1.1) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from transformers->whisperx==3.1.1) (6.0)\n",
      "Requirement already satisfied: requests in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from transformers->whisperx==3.1.1) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from transformers->whisperx==3.1.1) (0.3.2)\n",
      "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for lightning-utilities<2.0,>=0.8.0 from https://files.pythonhosted.org/packages/7d/84/fce34a549e2f795b3a0427e7dd40719dd4f00036e50ba58198a5a706eb75/lightning_utilities-0.10.1-py3-none-any.whl.metadata\n",
      "  Downloading lightning_utilities-0.10.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for pytorch-lightning from https://files.pythonhosted.org/packages/8b/1a/bf51e48e9c60e892ea97dc8198d8a32cba94d014c52baca1c93599bfe30c/pytorch_lightning-2.2.0.post0-py3-none-any.whl.metadata\n",
      "  Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/f3/bf/26deba06a4c910a85f78245cac7698f67cedd7efe00d04f6b3e1b3506a59/protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.11.1)\n",
      "Collecting typer[all]>=0.2.1 (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for typer[all]>=0.2.1 from https://files.pythonhosted.org/packages/bf/0e/c68adf10adda05f28a6ed7b9f4cd7b8e07f641b44af88ba72d9c89e4de7a/typer-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.0)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.8.10)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.7.2)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for optuna>=3.1 from https://files.pythonhosted.org/packages/4c/6a/219a431aaf81b3eb3070fd2d58116baa366d3072f43bbcc87dc3495b7546/optuna-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading optuna-3.5.0-py3-none-any.whl.metadata (17 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->whisperx==3.1.1) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.15.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.15.1)\n",
      "Collecting hyperpyyaml (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for hyperpyyaml from https://files.pythonhosted.org/packages/33/c9/751b6401887f4b50f9307cc1e53d287b3dc77c375c126aeb6335aff73ccb/HyperPyYAML-1.2.2-py3-none-any.whl.metadata\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting sentencepiece (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/de/42/ae30952c4a0bd773e90c9bf2579f5533037c886dfc8ec68133d5694f4dd2/sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from sympy->torch>=2->whisperx==3.1.1) (1.3.0)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting librosa>=0.6.0 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for librosa>=0.6.0 from https://files.pythonhosted.org/packages/e2/a2/4f639c1168d7aada749a896afb4892a831e2041bebdcf636aebfe9e86556/librosa-0.10.1-py3-none-any.whl.metadata\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for torch-pitch-shift>=1.2.2 from https://files.pythonhosted.org/packages/e6/b3/42b46bccba56baecea9678d8feea09f21777f67ab397719409e036f03058/torch_pitch_shift-1.2.4-py3-none-any.whl.metadata\n",
      "  Downloading torch_pitch_shift-1.2.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=2->whisperx==3.1.1) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx==3.1.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx==3.1.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx==3.1.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx==3.1.1) (2023.7.22)\n",
      "Requirement already satisfied: pycparser in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.21)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from fsspec->torch>=2->whisperx==3.1.1) (3.8.5)\n",
      "Collecting audioread>=2.1.9 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for audioread>=2.1.9 from https://files.pythonhosted.org/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.57.1)\n",
      "Collecting pooch>=1.0 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for pooch>=1.0 from https://files.pythonhosted.org/packages/f4/72/8ae0f1ba4ce6a4f6d4d01a60a9fdf690fde188c45c1872b0b4ddb0607ace/pooch-1.8.1-py3-none-any.whl.metadata\n",
      "  Downloading pooch-1.8.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/d0/79/c93daceac24cd6830333d9f3d04716115240ef3be4e8d8ece511afbcf417/soxr-0.3.7-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading soxr-0.3.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.9)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/7f/50/9fb3a5c80df6eb6516693270621676980acd6d5a9a7efdbfa273f8d616c7/alembic-1.13.1-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for colorlog from https://files.pythonhosted.org/packages/f3/18/3e867ab37a24fdf073c1617b9c7830e06ec270b1ea4694a624038fc40a03/colorlog-6.8.2-py3-none-any.whl.metadata\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.39)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.0)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for primePy>=1.3 from https://files.pythonhosted.org/packages/74/c1/bb7e334135859c3a92ec399bc89293ea73f28e815e35b43929c8db6af030/primePy-1.3-py3-none-any.whl.metadata\n",
      "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.4.6)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for shellingham<2.0.0,>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for ruamel.yaml>=0.17.28 from https://files.pythonhosted.org/packages/73/67/8ece580cc363331d9a53055130f86b096bf16e38156e33b1d3014fffda6b/ruamel.yaml-0.18.6-py3-none-any.whl.metadata\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.2.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/2b/8d/9f11d0b9ac521febb806e7f30dc5982d0f4f5821217712c59005fbc5c1e3/Mako-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.40.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.10.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Obtaining dependency information for ruamel.yaml.clib>=0.2.7 from https://files.pythonhosted.org/packages/01/b0/4ddef56e9f703d7909febc3a421d709a3482cda25826816ec595b73e3847/ruamel.yaml.clib-0.2.8-cp311-cp311-macosx_13_0_arm64.whl.metadata\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp311-cp311-macosx_13_0_arm64.whl.metadata (2.2 kB)\n",
      "Downloading faster_whisper-1.0.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.audio-3.1.1-py2.py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading av-11.0.0-cp311-cp311-macosx_11_0_arm64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.2.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Downloading ctranslate2-4.0.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.2.0.post0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.database-5.0.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading pytorch_metric_learning-2.4.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_audiomentations-0.11.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
      "Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading soxr-0.3.7-cp311-cp311-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.5/390.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.8-cp311-cp311-macosx_13_0_arm64.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.5/134.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: whisperx, antlr4-python3-runtime, docopt, julius\n",
      "  Building wheel for whisperx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisperx: filename=whisperx-3.1.1-py3-none-any.whl size=38612 sha256=3c5b5663fc91f21b94f325146260e852dc97ddaa90bfd665aacbf338cb056bd9\n",
      "  Stored in directory: /private/var/folders/3q/tc_6_w3n2l76g5bvv9nc8jl80000gn/T/pip-ephem-wheel-cache-yvlolfvn/wheels/a7/c5/cb/f337e8d88ff15af9ece963912a153e4132d00e7cdd61f48416\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4e9931ecff4973916415664e9afbad6f7d32e606bf3459e59c00085576460511\n",
      "  Stored in directory: /Users/kulyashdahiya/Library/Caches/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=2e870326d22ee1c30c9a200ee2c82c870a68cf6116bbf341fd53177e258b3adc\n",
      "  Stored in directory: /Users/kulyashdahiya/Library/Caches/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21879 sha256=070a8f84aae0cd6a5e4e32a1f370f94b8f7931c064698a11ed6ed28394224e5f\n",
      "  Stored in directory: /Users/kulyashdahiya/Library/Caches/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
      "Successfully built whisperx antlr4-python3-runtime docopt julius\n",
      "Installing collected packages: sentencepiece, primePy, flatbuffers, docopt, antlr4-python3-runtime, typer, soxr, shellingham, semver, ruamel.yaml.clib, protobuf, omegaconf, Mako, lightning-utilities, humanfriendly, einops, ctranslate2, colorlog, av, audioread, tensorboardX, soundfile, ruamel.yaml, rich, pyannote.core, pooch, coloredlogs, alembic, torchmetrics, torchaudio, pytorch-metric-learning, optuna, onnxruntime, librosa, julius, hyperpyyaml, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.database, faster-whisper, torch-audiomentations, pyannote.pipeline, pyannote.metrics, lightning, pyannote.audio, whisperx\n",
      "  Attempting uninstall: ruamel.yaml\n",
      "    Found existing installation: ruamel.yaml 0.17.21\n",
      "    Uninstalling ruamel.yaml-0.17.21:\n",
      "      Successfully uninstalled ruamel.yaml-0.17.21\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 23.7.4 requires ruamel-yaml<0.18,>=0.11.14, but you have ruamel-yaml 0.18.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.2 alembic-1.13.1 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 audioread-3.0.1 av-11.0.0 coloredlogs-15.0.1 colorlog-6.8.2 ctranslate2-4.0.0 docopt-0.6.2 einops-0.7.0 faster-whisper-1.0.0 flatbuffers-23.5.26 humanfriendly-10.0 hyperpyyaml-1.2.2 julius-0.2.7 librosa-0.10.1 lightning-2.2.0.post0 lightning-utilities-0.10.1 omegaconf-2.3.0 onnxruntime-1.17.1 optuna-3.5.0 pooch-1.8.1 primePy-1.3 protobuf-4.25.3 pyannote.audio-3.1.1 pyannote.core-5.0.0 pyannote.database-5.0.1 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.2.0.post0 pytorch-metric-learning-2.4.1 rich-13.7.1 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 semver-3.0.2 sentencepiece-0.2.0 shellingham-1.5.4 soundfile-0.12.1 soxr-0.3.7 speechbrain-1.0.0 tensorboardX-2.6.2.2 torch-audiomentations-0.11.1 torch-pitch-shift-1.2.4 torchaudio-2.2.1 torchmetrics-1.3.1 typer-0.9.0 whisperx-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/m-bain/whisperx.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63aef758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e4b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/kulyashdahiya/Beginning/AI/AudioTranscript\n",
      "File Path: /Users/kulyashdahiya/Beginning/AI/AudioTranscript/trimmed_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulyashdahiya/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m output_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/translated_output.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m outputfile_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_directory, output_file_name)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output_file:\n\u001b[1;32m     26\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m translated_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "# !sudo apt update && sudo apt install ffmpeg\n",
    "\n",
    "# pip install -U openai-whisper\n",
    "# pip install setuptools-rust\n",
    "# pip install pydub\n",
    "\n",
    "import os\n",
    "import whisper\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)\n",
    "\n",
    "input_file_name = \"audio.mp3\"\n",
    "file_path = os.path.join(current_directory, input_file_name)\n",
    "print(\"File Path:\", file_path)\n",
    "\n",
    "\n",
    "model = whisper.load_model(\"large\")\n",
    "result = model.transcribe(file_path, language=\"Hindi\", task=\"translate\")\n",
    "\n",
    "translated_text = result[\"text\"]\n",
    "\n",
    "output_file_name = \"output.txt\"\n",
    "output_file_path = os.path.join(current_directory, output_file_name)\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    sentences = translated_text.split(\".\")\n",
    "    for sentence in sentences:\n",
    "        output_file.write(sentence.strip() + \".\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
